{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a50bbf-b1fb-4eb2-86b1-a06234c1364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202573bb-b6f2-4380-81f9-bd80f20b517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i - 1 for i in loadmat('./imagelabels.mat')['labels'][0].tolist()]\n",
    "list_dirs = sorted(os.listdir('./102flowers/jpg'))\n",
    "img_to_lbl = dict(zip(list_dirs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2318883d-eae6-4b72-820e-b2f86e61726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 0:00:01.356736\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://www.robots.ox.ac.uk/~vgg/data/flowers/102/categories.html')\n",
    "print(response.ok, response.elapsed)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1756f6-2283-4656-b8bb-82aa7df1fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "table = soup.table\n",
    "body = table.tbody\n",
    "cnt = 0\n",
    "for tr in body.find_all('tr'):\n",
    "    imL, imC, imR = None, None, None\n",
    "    lblL, lblC, lblR = None, None, None\n",
    "    for td in tr.find_all('td'):\n",
    "        if td.get('class')[0] == 'imL': \n",
    "            imL = td.img.get('src')\n",
    "            imL = 'image_' + imL.split('/')[-1].split('_')[-1]\n",
    "        if td.get('class')[0] == 'imC':\n",
    "            imC = td.img.get('src')\n",
    "            imC = 'image_' + imC.split('/')[-1].split('_')[-1]\n",
    "        if td.get('class')[0] == 'imR':\n",
    "            imR = td.img.get('src')\n",
    "            imR = 'image_' + imR.split('/')[-1].split('_')[-1]\n",
    "\n",
    "        if 'labL' in td.get('class'):\n",
    "            lblL = td.text\n",
    "\n",
    "        if 'labC' in td.get('class'):\n",
    "            lblC = td.text\n",
    "\n",
    "        if 'labR' in td.get('class'):\n",
    "            lblR = td.text\n",
    "\n",
    "    lbl_numL = img_to_lbl[imL]\n",
    "    lbl_numC = img_to_lbl[imC]\n",
    "    lbl_numR = img_to_lbl[imR]\n",
    "    result[lbl_numL] = lblL\n",
    "    result[lbl_numC] = lblC\n",
    "    result[lbl_numR] = lblR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3f73a1-fca7-4ed9-9e8f-c9cc83c3ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_names.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Label', 'Name'])\n",
    "    for k, v in sorted(result.items()):\n",
    "        writer.writerow([k, v])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6885e-4a97-487d-b1c2-61999666e85c",
   "metadata": {},
   "source": [
    "## Create a Tensorflow Lite (TFLITE) output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91dcfdba-69aa-4433-910b-8e990ab14f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5593314d-b9a8-4f5a-8fd0-e0561ab06392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications.efficientnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6248583c-bfd6-4296-944f-49b4f11845d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Functio  (None, 7, 7, 1280)        5919312   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 102)               130662    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6049974 (23.08 MB)\n",
      "Trainable params: 5564410 (21.23 MB)\n",
      "Non-trainable params: 485564 (1.85 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./saves/tf/02_efficient_net_0.99.tf/')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c93c92f-ed2f-47b3-a9df-de782f489e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = keras.Sequential([\n",
    "    keras.layers.Lambda(lambda x: preprocess_input(x)),\n",
    "    model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f8dfcd-90a5-436e-941c-15b793e5c723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%1.000 passion flower\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./102flowers/jpg/image_00001.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))[None, ...]\n",
    "pred = predict_model(tf.cast(img, tf.float32))\n",
    "print(f'%{np.max(pred):.3f} {result[np.argmax(pred)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af50a66b-5a32-47ec-9154-e2832b604fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./saves/temp/temp.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saves/temp/temp.tf/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./saves/temp\n",
    "predict_model.save('./saves/temp/temp.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bdff4b9-b3c6-46b6-a227-99118f256a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 196, Total Ops 533, % non-converted = 36.77 %\n",
      " * 196 ARITH ops\n",
      "\n",
      "- arith.constant:  196 occurrences  (f32: 187, i32: 9)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 15)\n",
      "  (f32: 75)\n",
      "  (f32: 16)\n",
      "  (f32: 1)\n",
      "  (f32: 71)\n",
      "  (f32: 17)\n",
      "  (f32: 73)\n",
      "  (i32: 16)\n",
      "  (f32: 16)\n",
      "  (i32: 16)\n",
      "  (f32: 1)\n",
      "  (i32: 16)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('./saves/temp/temp.tf')\n",
    "tflite = converter.convert()\n",
    "with open('./saves/tflite/efficientnet_0.99.tflite', 'wb') as file:\n",
    "    file.write(tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d37d1faa-4b02-44b8-a797-da5e00a4f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./saves/temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f48287-66cd-440d-892d-62ab93e2a517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
